# Local LLM Setup

This directory contains instructions and scripts for running a local LLM using Ollama.

## Installation

1.  **Install Ollama:** Follow the instructions for your operating system on the official Ollama website: [https://ollama.com/](https://ollama.com/)

## Usage

1.  **Run the LLM:** To start the LLM, execute the following command in your terminal:
```
bash
    ollama run llama3
    
```
2. Run the run_model.sh file.